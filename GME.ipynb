{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a69534-917d-45d3-8077-d0d32ccbe5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 tables on the page\n",
      "Examining table 1...\n",
      "Table 1 contains relevant keywords\n",
      "Found data: 2025 - $3,823\n",
      "Found data: 2024 - $5,273\n",
      "Found data: 2023 - $5,927\n",
      "Found data: 2022 - $6,011\n",
      "Found data: 2021 - $5,090\n",
      "Found data: 2020 - $6,466\n",
      "Found data: 2019 - $8,285\n",
      "Found data: 2018 - $8,547\n",
      "Found data: 2017 - $7,965\n",
      "Found data: 2016 - $9,364\n",
      "Found data: 2015 - $9,296\n",
      "Found data: 2014 - $9,040\n",
      "Found data: 2013 - $8,887\n",
      "Found data: 2012 - $9,551\n",
      "Found data: 2011 - $9,474\n",
      "Found data: 2010 - $9,078\n",
      "Found data: 2009 - $8,806\n",
      "Examining table 2...\n",
      "Table 2 contains relevant keywords\n",
      "Found data: 2025-04-30 - $732\n",
      "Found data: 2025-01-31 - $1,283\n",
      "Found data: 2024-10-31 - $860\n",
      "Found data: 2024-07-31 - $798\n",
      "Found data: 2024-04-30 - $882\n",
      "Found data: 2024-01-31 - $1,794\n",
      "Found data: 2023-10-31 - $1,078\n",
      "Found data: 2023-07-31 - $1,164\n",
      "Found data: 2023-04-30 - $1,237\n",
      "Found data: 2023-01-31 - $2,226\n",
      "Found data: 2022-10-31 - $1,186\n",
      "Found data: 2022-07-31 - $1,136\n",
      "Found data: 2022-04-30 - $1,378\n",
      "Found data: 2022-01-31 - $2,254\n",
      "Found data: 2021-10-31 - $1,297\n",
      "Found data: 2021-07-31 - $1,183\n",
      "Found data: 2021-04-30 - $1,277\n",
      "Found data: 2021-01-31 - $2,122\n",
      "Found data: 2020-10-31 - $1,005\n",
      "Found data: 2020-07-31 - $942\n",
      "Found data: 2020-04-30 - $1,021\n",
      "Found data: 2020-01-31 - $2,194\n",
      "Found data: 2019-10-31 - $1,439\n",
      "Found data: 2019-07-31 - $1,286\n",
      "Found data: 2019-04-30 - $1,548\n",
      "Found data: 2019-01-31 - $3,063\n",
      "Found data: 2018-10-31 - $1,935\n",
      "Found data: 2018-07-31 - $1,501\n",
      "Found data: 2018-04-30 - $1,786\n",
      "Found data: 2018-01-31 - $2,825\n",
      "Found data: 2017-10-31 - $1,989\n",
      "Found data: 2017-07-31 - $1,688\n",
      "Found data: 2017-04-30 - $2,046\n",
      "Found data: 2017-01-31 - $2,403\n",
      "Found data: 2016-10-31 - $1,959\n",
      "Found data: 2016-07-31 - $1,632\n",
      "Found data: 2016-04-30 - $1,972\n",
      "Found data: 2016-01-31 - $3,525\n",
      "Found data: 2015-10-31 - $2,016\n",
      "Found data: 2015-07-31 - $1,762\n",
      "Found data: 2015-04-30 - $2,061\n",
      "Found data: 2015-01-31 - $3,476\n",
      "Found data: 2014-10-31 - $2,092\n",
      "Found data: 2014-07-31 - $1,731\n",
      "Found data: 2014-04-30 - $1,996\n",
      "Found data: 2014-01-31 - $3,684\n",
      "Found data: 2013-10-31 - $2,107\n",
      "Found data: 2013-07-31 - $1,384\n",
      "Found data: 2013-04-30 - $1,865\n",
      "Found data: 2013-01-31 - $3,562\n",
      "Found data: 2012-10-31 - $1,773\n",
      "Found data: 2012-07-31 - $1,550\n",
      "Found data: 2012-04-30 - $2,002\n",
      "Found data: 2012-01-31 - $3,579\n",
      "Found data: 2011-10-31 - $1,947\n",
      "Found data: 2011-07-31 - $1,744\n",
      "Found data: 2011-04-30 - $2,281\n",
      "Found data: 2011-01-31 - $3,693\n",
      "Found data: 2010-10-31 - $1,899\n",
      "Found data: 2010-07-31 - $1,799\n",
      "Found data: 2010-04-30 - $2,083\n",
      "Found data: 2010-01-31 - $3,524\n",
      "Found data: 2009-10-31 - $1,835\n",
      "Found data: 2009-07-31 - $1,739\n",
      "Found data: 2009-04-30 - $1,981\n",
      "Found data: 2009-01-31 - $3,492\n",
      "Examining table 3...\n",
      "Table 3 contains relevant keywords\n",
      "Examining table 4...\n",
      "Examining table 5...\n",
      "Table 5 contains relevant keywords\n",
      "Examining table 6...\n",
      "Table 6 contains relevant keywords\n",
      "Successfully extracted 83 data points\n",
      "\n",
      "GameStop Revenue - Last 5 Rows:\n",
      "          Date  Revenue\n",
      "78  2010-01-31     3524\n",
      "79  2009-10-31     1835\n",
      "80  2009-07-31     1739\n",
      "81  2009-04-30     1981\n",
      "82  2009-01-31     3492\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# URL for GameStop revenue data (Macrotrends)\n",
    "url = \"https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue\"\n",
    "\n",
    "# Send HTTP request with headers to mimic a browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "html_data = response.text\n",
    "\n",
    "# Parse HTML\n",
    "soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "\n",
    "# Try different approaches to find revenue data\n",
    "# Approach 1: Look for tables with specific text in headers or nearby elements\n",
    "revenue_data = []\n",
    "dates = []\n",
    "revenues = []\n",
    "\n",
    "# Look for all tables\n",
    "all_tables = soup.find_all('table')\n",
    "print(f\"Found {len(all_tables)} tables on the page\")\n",
    "\n",
    "# Try to find tables with financial data\n",
    "for i, table in enumerate(all_tables):\n",
    "    print(f\"Examining table {i+1}...\")\n",
    "    \n",
    "    # Check table headers or content for revenue-related terms\n",
    "    if any(term in table.text.lower() for term in ['revenue', 'quarterly', 'annual', 'gamestop']):\n",
    "        print(f\"Table {i+1} contains relevant keywords\")\n",
    "        \n",
    "        # Extract rows\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 2:  # Ensure there are at least 2 columns\n",
    "                date = cols[0].text.strip()\n",
    "                revenue = cols[1].text.strip()\n",
    "                \n",
    "                # Check if this looks like a date and revenue\n",
    "                if re.match(r'\\d{4}-\\d{2}-\\d{2}|\\w+ \\d{4}|\\d{4}', date) and re.search(r'\\d', revenue):\n",
    "                    dates.append(date)\n",
    "                    revenues.append(revenue)\n",
    "                    print(f\"Found data: {date} - {revenue}\")\n",
    "\n",
    "# If we couldn't find data in tables, try looking for structured data in scripts\n",
    "if not dates:\n",
    "    print(\"Trying alternative approach: looking for data in scripts...\")\n",
    "    scripts = soup.find_all('script')\n",
    "    for script in scripts:\n",
    "        if script.string and 'quarterly' in script.string.lower() and 'revenue' in script.string.lower():\n",
    "            # Try to extract JSON data\n",
    "            match = re.search(r'var\\s+originalData\\s*=\\s*(\\[.*?\\]);', script.string, re.DOTALL)\n",
    "            if match:\n",
    "                import json\n",
    "                try:\n",
    "                    data = json.loads(match.group(1))\n",
    "                    for item in data:\n",
    "                        if 'date' in item and 'revenue' in item:\n",
    "                            dates.append(item['date'])\n",
    "                            revenues.append(item['revenue'])\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Found potential data but couldn't parse JSON\")\n",
    "\n",
    "# Create dataframe if we have data\n",
    "if dates and revenues:\n",
    "    print(f\"Successfully extracted {len(dates)} data points\")\n",
    "    gme_revenue = pd.DataFrame({\"Date\": dates, \"Revenue\": revenues})\n",
    "    \n",
    "    # Clean data (remove commas, $ signs, and empty values)\n",
    "    gme_revenue[\"Revenue\"] = gme_revenue[\"Revenue\"].str.replace(r'[\\$,]', '', regex=True)\n",
    "    gme_revenue = gme_revenue[gme_revenue[\"Revenue\"] != \"\"]\n",
    "    \n",
    "    # Convert to numeric\n",
    "    gme_revenue[\"Revenue\"] = pd.to_numeric(gme_revenue[\"Revenue\"], errors='coerce')\n",
    "    gme_revenue = gme_revenue.dropna()\n",
    "    \n",
    "    # Display last 5 rows\n",
    "    print(\"\\nGameStop Revenue - Last 5 Rows:\")\n",
    "    print(gme_revenue.tail())\n",
    "else:\n",
    "    print(\"\\nCould not extract revenue data. The website structure has likely changed significantly.\")\n",
    "    print(\"Consider using an official financial data API instead of web scraping for more reliable results.\")\n",
    "    print(\"Alternatives: Yahoo Finance API, Alpha Vantage, or Financial Modeling Prep API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424fd2a-00ca-4f12-af6d-6b9dde1102c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
